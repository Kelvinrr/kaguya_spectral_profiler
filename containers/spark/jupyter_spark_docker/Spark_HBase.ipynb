{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark import SparkContext, SparkConf, SQLContext\n",
    "\n",
    "#os.environ['PYSPARK_SUBMIT_ARGS'] = (\"--files hbase-site.xml --driver-class-path /usr/local/hbase-1.2.6/lib/*\"  \" pyspark-shell\") \n",
    "\n",
    "conf = SparkConf()\n",
    "conf.set('spark.driver.extraClassPath', '/usr/local/hbase-1.2.6/lib/*')\n",
    "conf.set('spark.executor.extraClassPath', '/usr/local/hbase-1.2.6/lib/*')\n",
    "\n",
    "sc = SparkContext(master='spark://master:7077', conf=conf)\n",
    "sqlcontext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = ''.join(\"\"\"{\n",
    "    \"table\":{\"namespace\":\"default\", \"name\":\"simple\"},\n",
    "    \"rowkey\":\"key\",\n",
    "    \"columns\":{\n",
    "      \"key\": {\"cf\":\"rowkey\", \"col\":\"key\", \"type\":\"string\"},\n",
    "      \"col1\": {\"cf\":\"cf1\", \"col\":\"a\", \"type\":\"string\"}\n",
    "    }\n",
    "}\"\"\")\n",
    "df = sqlcontext.read.\\\n",
    "            options(catalog=catalog).\\\n",
    "            format('org.apache.spark.sql.execution.datasources.hbase').\\\n",
    "            load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|     key|\n",
      "+--------+\n",
      "|row12463|\n",
      "|row26354|\n",
      "|row26728|\n",
      "|row32901|\n",
      "|row37540|\n",
      "|row39225|\n",
      "|row60684|\n",
      "|row68003|\n",
      "|row81977|\n",
      "|row88424|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"key\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "| col1|\n",
      "+-----+\n",
      "|46708|\n",
      "|58502|\n",
      "|92206|\n",
      "|33181|\n",
      "|13947|\n",
      "|74306|\n",
      "|25358|\n",
      "|83632|\n",
      "|93632|\n",
      "|26186|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"col1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|     key| col1|\n",
      "+--------+-----+\n",
      "|row12463|46708|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.key == 'row12463').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|     key| col1|\n",
      "+--------+-----+\n",
      "|row26728|92206|\n",
      "|row32901|33181|\n",
      "|row37540|13947|\n",
      "|row39225|74306|\n",
      "|row60684|25358|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter((df.key > 'row26354') & (df.key < 'row68003')).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
